---
title: AI Stuff
template: 'post'
image: 'https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/17_result_sherlock.jpg?raw=true'
alt: 'mona lisa ai altered'
draft: false
slug: '/ai/stuff'
category: 'AI'
tags:
  - 'AI Stuff'
  - 'Art'
description: 'Some stuff about AI.'
---

### Links

- [How Google Maps knows which direction you are facing](https://ai.googleblog.com/2019/02/using-global-localization-to-improve.html)
- [What are Symbolic and Imperative APIs in TensorFlow 2.0?](https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021)
- [Data-sets for that random time when you decide to do this stuff](https://www.tensorflow.org/datasets)
- [Learning GAN's - a form of generative art](https://www.tensorflow.org/beta/tutorials/generative/dcgan)
- [Image to image translation](https://phillipi.github.io/pix2pix/)
- [Glow - reversible generative models](https://openai.com/blog/glow/)
- [A github library to... copy an element from a photo and paste it into a painting - deep painterly harmonization](https://github.com/luanfujun/deep-painterly-harmonization)
- [The first novel written by AI](https://singularityhub.com/2018/10/25/ai-wrote-a-road-trip-novel-is-it-a-good-read/#sm.00069qmis10ebdl7uan103cdtwnog)

### What I should use in the future

- Google AutoML
- TensorFlow 2.0 with Keras

### Deep learning and Machine learning

There are plenty of articles about it

## [Twitter ML workflows](https://blog.twitter.com/engineering/en_us/topics/insights/2018/ml-workflows.html)

## ML for Artists

### [Going deeper with inceptionism](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)

Instead of selecting in advance of the neuron you want to update. Feed it through the network, feed the pixels to make the activation go higher.

From:

![machine learning inceptionism example](https://3.bp.blogspot.com/-4Uj3hPFupok/VYIT6s_c9OI/AAAAAAAAAlc/_yGdbbsmGiw/s640/ibis.png)

#### Artists

Some machine learning artists:

http://www.miketyka.com/

http://genekogan.com/works

http://quasimondo.com/
#### [abraham.ai](http://abraham.ai/)

The speaker is trying to create a collective intelligence, a hive mind of human creativity.

He is working to do this with a generative art program that is running a model which is collectively controlled by a decentralised group of actors. Behaviour is emergent upon all of us. Output is a function of all of the people in the network.

So the basic premise is to decentralise a machine learning model. A neural network that is split among a group of people as a shared secret. A whole bunch of chunks that are useless by their selves but useful when they are all connected (a neural social network). Achieves uniqueness and originality. Model cannot be copied. Originality is the sum of all intelligences.

An analogy [an experiment done with jellybeans](https://blog.asmartbear.com/ignoring-the-wisdom-of-crowds.html)

- This experiment had a jar containing jellybeans and a certain number of people. Then, the experimenter asked each person how many jellybeans they thought the jar contained. And, the result was that when you take everyone's count and find the average, you get very close to the actual number. This is called _collective intelligence_.

- So, the goal is to do something along those lines.

#### The actual premise on the site:

**Abraham is an open project to create an autonomous artificial artist, a decentralized AI who generates art.**
