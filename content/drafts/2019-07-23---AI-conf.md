---
title: AI Conference
date: '2019-07-23'
template: 'draft'
draft: true
slug: '/posts/7-23-19/'
category: 'Stuff'
tags:
  - 'AI Conference'
  - 'Rough notes'
  - 'Needs redefining'
description: 'These are the notes I took at the AI conference. I need to look through it and figure out what is most important/of interest. I noted a lot of things that I need to spend some time reading about.'
---

## AI to Empower AI (Agent Intelligence)

### Real estate is software

Music can be thought of as software, etc. Why should real estate not also be?

- Aim to become the definitive data source for the real estate industry

### AI considerations

#### Life quality score

Quality of life you will get from your new place

- This can be assisted by selecting preferenes, and ranking them, to get customised places

#### Hot zones, Likely seller, Likely buyer, Virtual reality, Intelligent marketing, instant deal

Hot zones relates to specific locations/amenities connected to a place that historically get taken quickly. Compass assists sellers to conceptualise how they should sell this property.

Virtual reality tours with a bunch of hotspots that are clickable with info related (videos, text descriptions, etc.)

- Done with cameras that specialise in taking videos that scan the surroundings to create a dollhouse-like view of a place.

Compass Concierge literally brgins people in to redesign the apartment prior to listing the property. Contracting, putting beautiful furniture, etc. to improve the visual image sen on Compass for the buyers.

### Vision-based real estate price estimation

[Zestimate](https://www.zillow.com/zestimate/)

### AI Opportunity Map

Data conflation and integration

### [Home Data](https://www.bloomberg.com/graphics/property-prices/nyc/)

Shows a map with a variety of views such as average rent, house price, etc. in specific neighborhoods in NYC.

## Tensor Flow 2.0

### Building a model

Images are made of a bunch of pixels (colors), that can be then be represented as some form of matrix. With this data, a neural network can be created.

#### Deep learning

A deep neural network is data going through many layers of abstraction

- Take all the data and run an activation function on it.
- input layer -> activated neuron (layers) and an output layer.
  - ex. Edges(plain pixels) edges becoming simple shapes to more complex shapes to objects or people or things.

To create a neural network you need around 10 thousand examples (of whatever data you are working on figuring out... images, text (or natural language), or speech).

#### If you have smaller datasets, data is structured, and you have domain knowledge, or the data can already be explained

Use traditional ML methods. Not deep learning.

### Back to TensorFlow

Its for deep learning. It contains utilities for creating neural networks.

Main focuses are for efficient data use at Google. They made [this thing](https://ai.googleblog.com/2019/02/using-global-localization-to-improve.html) with it as well. Lots of other stuff as well.

It is also being used to see if distant objects are planets.

- How?
  - If there is an object in front of a distant star ( a planet or the like ) then the star will be slightly less bright than normal allowing us to be able to tell if a planet is revolving around that star (and I imagine the composition of it, etc.).

### But why TensorFlow 2.0

Easy, powerful (great performance), and scalable (Google uses it).

### Many smaller libraries for specific use cases within the TF ecosystem

### tf.keras

#### Ways to use it

For beginners: the Symbolic method

Each layer of the network is a single line of code.

Each layer is also built for you already.

As so:

![An example of how to use tensor flow 2.0](https://miro.medium.com/max/1260/0*XdVOKuyDWYHHzKvM)

Expert, missed it. But it is the imperative method.

Generally used for research, separation from the standard layers created throughout time.

### Performance improvements

`@tf.model`

Other little things you can do that automatically will drastically improve the performance.

### To play with TF

[Datasets](https://www.tensorflow.org/datasets)

### Trainings (layers) can be used on other models

As in, basic shapes (a square, a line, etc.) can be added to other models to automatically (in a way, as you skip previous steps) train it.

## Using a Bayesian Neural Network in the Detection of Exoplanets

### kbd+

World's fastest time-series database

### Q Language

## [Twitter ML workflows](https://blog.twitter.com/engineering/en_us/topics/insights/2018/ml-workflows.html)

### What is Apache Airflow?

[Github](https://github.com/apache/airflow)

[Site](https://airflow.apache.org/index.html)

### Kubeflow

[Site](https://www.kubeflow.org/docs/about/kubeflow/)

## ML for Artists

### [Visualising Convnets](https://ml4a.github.io/ml4a/visualizing_convnets/)

Some neorons can better understand certain parts of a picture.

### [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/abs/1312.6034)

### [Going deeper with inceptionism](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)

Instead of selecting in advance of the neuron you want to update. Feed it through the network, feed the pixels to make the activation go higher.

From:

![](https://3.bp.blogspot.com/-4Uj3hPFupok/VYIT6s_c9OI/AAAAAAAAAlc/_yGdbbsmGiw/s640/ibis.png)

To:

![](https://3.bp.blogspot.com/-4Uj3hPFupok/VYIT6s_c9OI/AAAAAAAAAlc/_yGdbbsmGiw/s640/ibis.png)

#### Artists

http://www.miketyka.com/

http://genekogan.com/works

http://quasimondo.com/

- loops, style transfer, cubist mirror, texture synthesis loops

#### Generative models

#### GANs and autoencoders

https://www.tensorflow.org/beta/tutorials/generative/dcgan

https://scholar.google.ca/citations?user=iYN86KEAAAAJ

#### Big GAN, mixing animals together

https://www.fastcompany.com/90244767/see-the-shockingly-realistic-images-made-by-googles-new-ai

https://arxiv.org/abs/1809.11096

#### Image-to-image translation

https://phillipi.github.io/pix2pix/

#### Invisible Cities

https://opendot.github.io/ml4a-invisible-cities/

#### vid2vid

https://opendot.github.io/ml4a-invisible-cities/

#### Glow

https://openai.com/blog/glow/

#### deep painter harmonization

https://github.com/luanfujun/deep-painterly-harmonization

#### abraham.ai

https://tinyurl.com/abraham-ai

Colletive intelligence, a hive mind of human creativity

Generative art program running a model that is collectively controlled by a decentralised group of actors. Behaviour is emergent upon all of us. Output is a function of all of the people in the network.

Decentralise a machine learning model. Neural network that is split among a group of people as a shared secret. A whole bunch of chunks that are useless by their selves but useful when they are all connected (a neural social network). Achieves unquness and originality. Model cannot be copied. Originality is the sum of all inteligences.

Openmined project. Create decentralised machine learning privatisation.

#### The collective imagination

Jellybean experiment - Take all the guesses and average is very close to the result. So the idea here is the creation of an artistic ideal.

## Google AutoML

### Democratize Machine Learning

Make machine learning less frustrating

Iterate quickly on ML apps

### Why is machine learning hard?

Difficult environment to setup. Big data does not work on small machines (a macbook).

Hyperparameter tuning

- Knobs you can tweak in ML

Model serving

### Why is deep learning hard?

You have to understand deep learning and learn how TensorFlow work

### Machine Learning today

#### Keras + Tensorflow 2.0

#### The cloud for handling massive data

#### Host your notebook in the cloud,

### AutoML Language processing
